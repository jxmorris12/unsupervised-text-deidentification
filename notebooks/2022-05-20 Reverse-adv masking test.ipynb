{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb3de424-f549-4e36-a470-190429feec00",
   "metadata": {},
   "source": [
    "### Reverse adv masking test\n",
    "\n",
    "I found a really weird result (end of previous notebook) that showed that the model can identify out 20% of people even when every non-stopword is masked out. So like 80% or more of the words are masked sometimes. Yet the adversarial examples at `k=1` mask out only 10% of words, and it seems to be the same words! \n",
    "\n",
    "What I'm wondering is if I can take the adversarial examples, then mask *more* words, but flip the prediction from incorrect to correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43a9bf30-4ab2-475e-8b68-43768dfc2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jxm3/research/deidentification/unsupervised-deidentification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27ebf771-ba18-4b62-8ece-946fbab620bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: set num_workers to 1, expect dataloader bottleneck\n",
      "Initializing WikipediaDataModule with num_workers = 1 and mask token `<mask>`\n",
      "loading wiki_bio[1.2.0] split train[:1024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset wiki_bio (/home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading wiki_bio[1.2.0] split val[:20%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset wiki_bio (/home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da)\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-793b771e10f80bbe.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-7d07543b6205ca87.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-7440752484ad8676.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-2c6f94b0d2dcc153.arrow\n"
     ]
    }
   ],
   "source": [
    "from dataloader import WikipediaDataModule\n",
    "import os\n",
    "\n",
    "num_cpus = os.cpu_count()\n",
    "\n",
    "dm = WikipediaDataModule(\n",
    "    document_model_name_or_path=\"roberta-base\",\n",
    "    profile_model_name_or_path=\"google/tapas-base\",\n",
    "    max_seq_length=128,\n",
    "    dataset_name='wiki_bio',\n",
    "    dataset_train_split='train[:1024]', # not used in this notebook\n",
    "    dataset_val_split='val[:20%]',\n",
    "    dataset_version='1.2.0',\n",
    "    word_dropout_ratio=0.0,\n",
    "    word_dropout_perc=0.0,\n",
    "    num_workers=1,\n",
    "    train_batch_size=64,\n",
    "    eval_batch_size=64\n",
    ")\n",
    "dm.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde6a746-26d3-49b3-9a9b-6de99d3fcb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model_5 from path: /home/jxm3/research/deidentification/unsupervised-deidentification/saves/ca__roberta__tapas__adv/deid-wikibio-2_default/236desyb_444/checkpoints/epoch=22-step=104718.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized model with learning_rate = 1e-05 and patience 1\n"
     ]
    }
   ],
   "source": [
    "from model import CoordinateAscentModel\n",
    "\n",
    "from model_cfg import model_paths_dict\n",
    "\n",
    "model_key = \"model_5\"\n",
    "\n",
    "checkpoint_path = model_paths_dict[model_key]\n",
    "print(f\"loading {model_key} from path:\", checkpoint_path)\n",
    "\n",
    "\n",
    "model = CoordinateAscentModel.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    document_model_name_or_path=\"roberta-base\",\n",
    "    profile_model_name_or_path=\"google/tapas-base\",\n",
    "    learning_rate=1e-5,\n",
    "    pretrained_profile_encoder=False,\n",
    "    lr_scheduler_factor=0.5,\n",
    "    lr_scheduler_patience=1,\n",
    "    train_batch_size=1,\n",
    "    num_workers=1,\n",
    "    gradient_clip_val=10.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e9b7a8-1d57-4c24-9f19-b0d520d3ba95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<AttackedText \"<mask> my name is Jack\">,\n",
       " <AttackedText \"Hello <mask> name is Jack\">,\n",
       " <AttackedText \"Hello my <mask> is Jack\">,\n",
       " <AttackedText \"Hello my name <mask> Jack\">,\n",
       " <AttackedText \"Hello my name is <mask>\">]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textattack\n",
    "\n",
    "class WordSwapSingleWord(textattack.transformations.word_swap.WordSwap):\n",
    "    \"\"\"Takes a sentence and transforms it by replacing with a single fixed word.\n",
    "    \"\"\"\n",
    "    single_word: str\n",
    "    def __init__(self, single_word: str = \"?\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.single_word = single_word\n",
    "\n",
    "    def _get_replacement_words(self, _word: str):\n",
    "        return [self.single_word]\n",
    "\n",
    "transformation = WordSwapSingleWord(single_word=dm.document_tokenizer.mask_token)\n",
    "transformation(textattack.shared.AttackedText(\"Hello my name is Jack\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d49feaa-e11b-46c1-94fa-f67e09db5f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              1.42it/s]\r"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "def precompute_profile_embeddings():\n",
    "    model.profile_model.cuda()\n",
    "    model.profile_model.eval()\n",
    "\n",
    "    model.val_profile_embeddings = np.zeros((len(dm.val_dataset), model.profile_embedding_dim))\n",
    "    for val_batch in tqdm.tqdm(dm.val_dataloader()[0], desc=\"Precomputing val embeddings\", colour=\"green\", leave=False):\n",
    "        with torch.no_grad():\n",
    "            profile_embeddings = model.forward_profile(batch=val_batch)\n",
    "        model.val_profile_embeddings[val_batch[\"text_key_id\"]] = profile_embeddings.cpu()\n",
    "    model.val_profile_embeddings = torch.tensor(model.val_profile_embeddings, dtype=torch.float32)\n",
    "    model.profile_model.train()\n",
    "\n",
    "precompute_profile_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd35c860-d884-4620-b8b5-699396134e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import transformers\n",
    "from model.model import Model\n",
    "\n",
    "class MyModelWrapper(textattack.models.wrappers.ModelWrapper):\n",
    "    model: Model\n",
    "    tokenizer: transformers.AutoTokenizer\n",
    "    profile_embeddings: torch.Tensor\n",
    "    max_seq_length: int\n",
    "    \n",
    "    def __init__(self, model: Model, tokenizer: transformers.AutoTokenizer, max_seq_length: int = 128):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.profile_embeddings = torch.tensor(model.val_profile_embeddings)\n",
    "        self.max_seq_length = max_seq_length\n",
    "                 \n",
    "    def to(self, device):\n",
    "        self.model.to(device)\n",
    "        self.profile_embeddings.to(device)\n",
    "        return self # so semantics `model = MyModelWrapper().to('cuda')` works properly\n",
    "\n",
    "    def __call__(self, text_input_list: List[str], batch_size=32):\n",
    "        model_device = next(self.model.parameters()).device\n",
    "        \n",
    "        doc_tokenized = self.tokenizer.batch_encode_plus(\n",
    "            text_input_list,\n",
    "            max_length=self.max_seq_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        doc_tokenized = {f'document__{k}': v for k,v in doc_tokenized.items()}\n",
    "        with torch.no_grad():\n",
    "            document_embeddings = self.model.forward_document(batch=doc_tokenized, document_type='document')\n",
    "            document_to_profile_logits = document_embeddings @ self.profile_embeddings.T.to(model_device)\n",
    "            document_to_profile_probs = torch.nn.functional.softmax(\n",
    "                document_to_profile_logits, dim=-1\n",
    "            )\n",
    "        assert document_to_profile_probs.shape == (len(text_input_list), len(self.profile_embeddings))\n",
    "        return document_to_profile_probs\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00b523c4-f729-48de-b05b-6955f127294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroundTruthTargetedClassification(textattack.goal_functions.ClassificationGoalFunction):\n",
    "    \"\"\"A targeted attack on classification models which attempts to maximize\n",
    "    the score of the target label.\n",
    "    Complete when the arget label is the predicted label.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, target_class=0, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def _is_goal_complete(self, model_output, _):\n",
    "        return (\n",
    "            self.ground_truth_output == model_output.argmax()\n",
    "        )\n",
    "\n",
    "    def _get_score(self, model_output, _):\n",
    "        if self.ground_truth_output < 0 or self.ground_truth_output >= len(model_output):\n",
    "            raise ValueError(\n",
    "                f\"target class set to {self.ground_truth_output} with {len(model_output)} classes.\"\n",
    "            )\n",
    "        else:\n",
    "            return model_output[self.ground_truth_output]\n",
    "\n",
    "    def extra_repr_keys(self):\n",
    "        if self.maximizable:\n",
    "            return [\"maximizable\"]\n",
    "        else:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e170ce0d-5e60-4bd0-bf1f-3112ba6d4424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import datasets\n",
    "\n",
    "class WikiDataset(textattack.datasets.Dataset):\n",
    "    examples: List[str]\n",
    "    \n",
    "    def __init__(self, dm: WikipediaDataModule, examples: List[str]):\n",
    "        self.shuffled = True\n",
    "        self.dm = dm\n",
    "        self.examples = examples\n",
    "        self.label_names = list(dm.val_dataset['name'])\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, i: int) -> Tuple[OrderedDict, int]:\n",
    "        input_dict = OrderedDict([\n",
    "            ('document', self.examples[i])\n",
    "        ])\n",
    "        return input_dict, self.dm.val_dataset[i]['text_key_id']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c49266e-9f9d-463e-90f5-ef1406cd6bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack.loggers import CSVLogger\n",
    "from textattack.shared import AttackedText\n",
    "\n",
    "import pandas as pd\n",
    "class CustomCSVLogger(CSVLogger):\n",
    "    \"\"\"Logs attack results to a CSV.\"\"\"\n",
    "\n",
    "    def log_attack_result(self, result: textattack.goal_function_results.ClassificationGoalFunctionResult):\n",
    "        # TODO print like 'mask1', 'mask2', ...\n",
    "        original_text, perturbed_text = result.diff_color(self.color_method)\n",
    "        original_text = original_text.replace(\"\\n\", AttackedText.SPLIT_TOKEN)\n",
    "        perturbed_text = perturbed_text.replace(\"\\n\", AttackedText.SPLIT_TOKEN)\n",
    "        result_type = result.__class__.__name__.replace(\"AttackResult\", \"\")\n",
    "        row = {\n",
    "            \"original_person\": result.original_result._processed_output[0],\n",
    "            \"original_text\": original_text,\n",
    "            \"perturbed_person\": result.perturbed_result._processed_output[0],\n",
    "            \"perturbed_text\": perturbed_text,\n",
    "            \"original_score\": result.original_result.score,\n",
    "            \"perturbed_score\": result.perturbed_result.score,\n",
    "            \"original_output\": result.original_result.output,\n",
    "            \"perturbed_output\": result.perturbed_result.output,\n",
    "            \"ground_truth_output\": result.original_result.ground_truth_output,\n",
    "            \"num_queries\": result.num_queries,\n",
    "            \"result_type\": result_type,\n",
    "        }\n",
    "        self.df = pd.concat([self.df, pd.DataFrame([row])], ignore_index=True)\n",
    "        self._flushed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e84d25b-eb72-437d-b95c-482ec5a9e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../adv_csvs/model_5/results_1_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e28d8e8-622b-4dbe-be28-34f47dbbb973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<mask> <mask> , (born march 14 , <mask>) is a professional squash player who represents france .\\nshe reached a career-high world ranking of world no. 101 in july <mask> .\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt = df['perturbed_text'].apply(lambda s: s.replace('<SPLIT>', '\\n')).to_list()\n",
    "print(len(pt))\n",
    "pt[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b870fe3c-c961-44b8-aeaf-8772041aa440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-c5104c9860b3>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.profile_embeddings = torch.tensor(model.val_profile_embeddings)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.MyModelWrapper at 0x7f682a66bb50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper = MyModelWrapper(model=model, tokenizer=dm.document_tokenizer)\n",
    "model_wrapper.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b36486fa-a8d7-4320-9206-f3ec3c5de7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack.shared.validators import transformation_consists_of_word_swaps\n",
    "\n",
    "class MaskModification(textattack.constraints.PreTransformationConstraint):\n",
    "    \"\"\"A constraint disallowing the modification of 'mask' words.\"\"\"\n",
    "    \n",
    "    def _get_modifiable_indices(self, current_text):\n",
    "        \"\"\"Returns the word indices in ``current_text`` which are able to be\n",
    "        modified.\"\"\"\n",
    "        non_mask_indices = set()\n",
    "        for i, word in enumerate(current_text.words):\n",
    "            if word.lower() not in ['mask', '[mask]', '<mask>']:\n",
    "                non_mask_indices.add(i)\n",
    "        return non_mask_indices\n",
    "\n",
    "    def check_compatibility(self, transformation):\n",
    "        \"\"\"The stopword constraint only is concerned with word swaps since\n",
    "        paraphrasing phrases containing stopwords is OK.\n",
    "        Args:\n",
    "            transformation: The ``Transformation`` to check compatibility with.\n",
    "        \"\"\"\n",
    "        return transformation_consists_of_word_swaps(transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "afb7a853-e6c6-4eeb-8e4e-46ae841d7302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: No entry found for goal function <class '__main__.GroundTruthTargetedClassification'>.\n",
      "textattack: Unknown if model of class <class 'model.coordinate_ascent.CoordinateAscentModel'> compatible with goal function <class '__main__.GroundTruthTargetedClassification'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): BeamSearch(\n",
      "    (beam_width):  4\n",
      "  )\n",
      "  (goal_function):  GroundTruthTargetedClassification\n",
      "  (transformation):  WordSwapSingleWord\n",
      "  (constraints): \n",
      "    (0): RepeatModification\n",
      "    (1): MaskModification\n",
      "    (2): MaxWordIndexModification(\n",
      "        (max_length):  128\n",
      "      )\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|â–ˆ         | 1/10 [00:00<00:02,  3.28it/s]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:  10%|â–ˆ         | 1/10 [00:00<00:02,  3.22it/s]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:  20%|â–ˆâ–ˆ        | 2/10 [00:00<00:02,  3.82it/s]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 0 / 2:  20%|â–ˆâ–ˆ        | 2/10 [00:00<00:02,  3.79it/s]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 21 / 1 / 0 / 22:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [06:26<02:20, 17.56s/it]\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 3 / 0 / 0 / 3:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:04<00:06,  1.01s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 4 / 0 / 0 / 4:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:04<00:06,  1.01s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 5 / 0 / 0 / 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:04<00:04,  1.21it/s]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 5 / 0 / 0 / 5:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:07<00:05,  1.28s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 5 / 1 / 0 / 6:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:07<00:05,  1.28s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 6 / 1 / 0 / 7:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:09<00:04,  1.36s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 6 / 1 / 0 / 7:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:09<00:02,  1.23s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 7 / 1 / 0 / 8:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:09<00:02,  1.23s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 8 / 1 / 0 / 9:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:09<00:01,  1.11s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 8 / 1 / 0 / 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.02s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 9 / 1 / 0 / 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 9      |\n",
      "| Number of failed attacks:     | 1      |\n",
      "| Number of skipped attacks:    | 0      |\n",
      "| Original accuracy:            | 100.0% |\n",
      "| Accuracy under attack:        | 10.0%  |\n",
      "| Attack success rate:          | 90.0%  |\n",
      "| Average perturbed word %:     | 11.46% |\n",
      "| Average num. words per input: | 37.2   |\n",
      "| Avg num queries:              | 254.7  |\n",
      "+-------------------------------+--------+"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "textattack: Logging to CSV at path results.csv\n",
      "textattack: CSVLogger exiting without calling flush().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_person</th>\n",
       "      <th>original_text</th>\n",
       "      <th>perturbed_person</th>\n",
       "      <th>perturbed_text</th>\n",
       "      <th>original_score</th>\n",
       "      <th>perturbed_score</th>\n",
       "      <th>original_output</th>\n",
       "      <th>perturbed_output</th>\n",
       "      <th>ground_truth_output</th>\n",
       "      <th>num_queries</th>\n",
       "      <th>result_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Halil hayreddin</td>\n",
       "      <td>pope [mask] iii [mask] alexandria (also known as <font color = blue>khail</font> [mask]) was the [mask] pope of alexandria [mask] patriarch of the see of st. mark (880 -- [mask]) .<SPLIT>in 882 , the governor of egypt , ahmad ibn tulun , forced khail to pay heavy contributions , forcing him to sell a church and some attached properties to the local jewish community .<SPLIT>this building was at one time believed to have later become the site of the cairo geniza .<SPLIT></td>\n",
       "      <td>Michael iii of alexandria</td>\n",
       "      <td>pope [mask] iii [mask] alexandria (also known as <<font color = red>mask</font>> [mask]) was the [mask] pope of alexandria [mask] patriarch of the see of st. mark (880 -- [mask]) .<SPLIT>in 882 , the governor of egypt , ahmad ibn tulun , forced khail to pay heavy contributions , forcing him to sell a church and some attached properties to the local jewish community .<SPLIT>this building was at one time believed to have later become the site of the cairo geniza .<SPLIT></td>\n",
       "      <td>0.405610</td>\n",
       "      <td>0.918142</td>\n",
       "      <td>6582</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Liu xiaolong</td>\n",
       "      <td>[mask] [mask] is a <font color = gray>male</font> former [mask] <font color = gray>tennis</font> <font color = gray>player</font> from china .<SPLIT></td>\n",
       "      <td>Hui jun</td>\n",
       "      <td>[mask] [mask] is a <<font color = green>mask</font>> former [mask] <<font color = green>mask</font>> <<font color = green>mask</font>> from china .<SPLIT></td>\n",
       "      <td>0.015369</td>\n",
       "      <td>0.179927</td>\n",
       "      <td>10388</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adem bÃ¼yÃ¼k</td>\n",
       "      <td>[mask] [mask] (born 30 november [mask]) is a turkish professional footballer .<SPLIT>he currently plays as a striker <font color = brown>for</font> [mask] [mask] .<SPLIT></td>\n",
       "      <td>Okan Ã¶ztÃ¼rk</td>\n",
       "      <td>[mask] [mask] (born 30 november [mask]) is a turkish professional footballer .<SPLIT>he currently plays as a striker <<font color = blue>mask</font>> [mask] [mask] .<SPLIT></td>\n",
       "      <td>0.454004</td>\n",
       "      <td>0.600850</td>\n",
       "      <td>2279</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laura pomportes</td>\n",
       "      <td>[mask] [mask] , (born march <font color = pink>14</font> , [mask]) <font color = pink>is</font> a professional <font color = pink>squash</font> player <font color = pink>who</font> <font color = pink>represents</font> france .<SPLIT><font color = pink>she</font> <font color = pink>reached</font> a career-high <font color = pink>world</font> ranking of <font color = pink>world</font> <font color = pink>no</font>. <font color = pink>101</font> <font color = pink>in</font> <font color = pink>july</font> [mask] .<SPLIT></td>\n",
       "      <td>Marie stephan</td>\n",
       "      <td>[mask] [mask] , (born march <<font color = purple>mask</font>> , [mask]) <<font color = purple>mask</font>> a professional <<font color = purple>mask</font>> player <<font color = purple>mask</font>> <<font color = purple>mask</font>> france .<SPLIT><<font color = purple>mask</font>> <<font color = purple>mask</font>> a career-high <<font color = purple>mask</font>> ranking of <<font color = purple>mask</font>> <<font color = purple>mask</font>>. <<font color = purple>mask</font>> <<font color = purple>mask</font>> <<font color = purple>mask</font>> [mask] .<SPLIT></td>\n",
       "      <td>0.023271</td>\n",
       "      <td>0.519180</td>\n",
       "      <td>4726</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>816</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lester k. fryer</td>\n",
       "      <td>[mask] [mask]. [mask] is a former <font color = yellow>democratic</font> member of the pennsylvania house of representatives .<SPLIT>he was born in butler [mask] michael and angela pitullio martino .<SPLIT></td>\n",
       "      <td>Leonard l. martino</td>\n",
       "      <td>[mask] [mask]. [mask] is a former <<font color = yellow>mask</font>> member of the pennsylvania house of representatives .<SPLIT>he was born in butler [mask] michael and angela pitullio martino .<SPLIT></td>\n",
       "      <td>0.296919</td>\n",
       "      <td>0.550956</td>\n",
       "      <td>3564</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Linda kozlowski</td>\n",
       "      <td>[mask] [mask] (<font color = gray>born</font> [mask] <font color = gray>8</font> , [mask]) <font color = gray>is</font> <font color = gray>an</font> <font color = gray>american</font> <font color = gray>stage</font> , <font color = gray>film</font> <font color = gray>and</font> <font color = gray>television</font> <font color = gray>actress</font> .<SPLIT><font color = gray>she</font> <font color = gray>is</font> <font color = gray>perhaps</font> <font color = gray>best</font> <font color = gray>known</font> <font color = gray>for</font> <font color = gray>portraying</font> <font color = gray>the</font> <font color = gray>female</font> <font color = gray>changeling</font> <font color = gray>on</font> '' '' .<SPLIT></td>\n",
       "      <td>Patrick sabongui</td>\n",
       "      <td>[mask] [mask] (<<font color = green>mask</font>> [mask] <<font color = green>mask</font>> , [mask]) <<font color = green>mask</font>> <<font color = green>mask</font>> <<font color = green>mask</font>> <<font color = green>mask</font>> , <<font color = green>mask</font>> <<font color = green>mask</font>> <<font color = green>mask</font>> <<font color = green>mask</font>> .<SPLIT><<font color = green>mask</font>> <<font color = green>mask</font>> <<font color = green>mask</font>> <<font color = green>mask</font>> <<font color = green>mask</font>> <<font color = green>mask</font>> <<font color = green>mask</font>> <<font color = green>mask</font>> <<font color = green>mask</font>> <<font color = green>mask</font>> <<font color = green>mask</font>> '' '' .<SPLIT></td>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>9248</td>\n",
       "      <td>10061</td>\n",
       "      <td>5</td>\n",
       "      <td>862</td>\n",
       "      <td>Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Josh hamilton</td>\n",
       "      <td>[mask] [mask] [mask] ([mask] [mask] [mask] , [mask]) , [mask] [mask] [mask] [mask] [mask] '' , [mask] [mask] [mask] [mask] [mask] [mask] [mask] [mask] [mask] [mask] [mask] [mask] <font color = red>of</font> major league [mask] (mlb) .<SPLIT>he <font color = red>bats</font> and <font color = red>throws</font> left-handed .<SPLIT>[mask] was <font color = red>drafted</font> by [mask] [mask] [mask] [mask] [mask] in the second round (52nd overall) of the 1999 major league baseball draft .<SPLIT>he made his major league debut in 2002 .<SPLIT>[mask] has more [mask] (121) than any other active baseball player .<SPLIT></td>\n",
       "      <td>Carl crawford</td>\n",
       "      <td>[mask] [mask] [mask] ([mask] [mask] [mask] , [mask]) , [mask] [mask] [mask] [mask] [mask] '' , [mask] [mask] [mask] [mask] [mask] [mask] [mask] [mask] [mask] [mask] [mask] [mask] <<font color = pink>mask</font>> major league [mask] (mlb) .<SPLIT>he <<font color = pink>mask</font>> and <<font color = pink>mask</font>> left-handed .<SPLIT>[mask] was <<font color = pink>mask</font>> by [mask] [mask] [mask] [mask] [mask] in the second round (52nd overall) of the 1999 major league baseball draft .<SPLIT>he made his major league debut in 2002 .<SPLIT>[mask] has more [mask] (121) than any other active baseball player .<SPLIT></td>\n",
       "      <td>0.124548</td>\n",
       "      <td>0.389187</td>\n",
       "      <td>9080</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>523</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>David morrell</td>\n",
       "      <td>[mask] [mask] (born [mask] neil morrison on 22 [mask] [mask]) is <font color = pink>a</font> [mask] musician and author , best known as the singer of <font color = pink>indie</font> punk band carter usm .<SPLIT></td>\n",
       "      <td>Jim bob</td>\n",
       "      <td>[mask] [mask] (born [mask] neil morrison on 22 [mask] [mask]) is <<font color = cyan>mask</font>> [mask] musician and author , best known as the singer of <<font color = cyan>mask</font>> punk band carter usm .<SPLIT></td>\n",
       "      <td>0.033356</td>\n",
       "      <td>0.320616</td>\n",
       "      <td>7586</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>102</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jeff faulkner</td>\n",
       "      <td>[mask] [mask] (born [mask] [mask] , [mask] in [mask] , <font color = blue>virginia</font>) is a former professional american football defensive lineman for the seattle seahawks , san diego chargers , new england patriots , baltimore ravens , and san francisco [mask] of the national football league .<SPLIT></td>\n",
       "      <td>Riddick parker</td>\n",
       "      <td>[mask] [mask] (born [mask] [mask] , [mask] in [mask] , <<font color = gray>mask</font>>) is a former professional american football defensive lineman for the seattle seahawks , san diego chargers , new england patriots , baltimore ravens , and san francisco [mask] of the national football league .<SPLIT></td>\n",
       "      <td>0.330582</td>\n",
       "      <td>0.838798</td>\n",
       "      <td>102</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mariya borovichenko</td>\n",
       "      <td>blessed [mask] [mask] [mask] t.o.s.d. -lrb-) was a catholic visionary and anchoress from [mask] (kotor) .<SPLIT>she was a teenage convert from orthodoxy of [mask] descent from [mask] (zeta) .<SPLIT>she became a dominican tertiary and was posthumously venerated as a saint in [mask] .<SPLIT>she was later beatified in <font color = blue>1934</font> .<SPLIT></td>\n",
       "      <td>Blessed osanna of cattaro -lrb- ozana kotorska -rrb-</td>\n",
       "      <td>blessed [mask] [mask] [mask] t.o.s.d. -lrb-) was a catholic visionary and anchoress from [mask] (kotor) .<SPLIT>she was a teenage convert from orthodoxy of [mask] descent from [mask] (zeta) .<SPLIT>she became a dominican tertiary and was posthumously venerated as a saint in [mask] .<SPLIT>she was later beatified in <<font color = brown>mask</font>> .<SPLIT></td>\n",
       "      <td>0.265053</td>\n",
       "      <td>0.752448</td>\n",
       "      <td>9342</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \n",
    "#  Initialize attack\n",
    "# \n",
    "\n",
    "from textattack import Attack\n",
    "from textattack.goal_functions import TargetedClassification\n",
    "from textattack.constraints.pre_transformation import RepeatModification, MaxWordIndexModification\n",
    "\n",
    "goal_function = GroundTruthTargetedClassification(model_wrapper)\n",
    "constraints = [\n",
    "    RepeatModification(),\n",
    "    MaskModification(),\n",
    "    MaxWordIndexModification(max_length=dm.max_seq_length),\n",
    "]\n",
    "transformation = WordSwapSingleWord(single_word=dm.document_tokenizer.mask_token)\n",
    "search_method = textattack.search_methods.BeamSearch(beam_width=4)\n",
    "\n",
    "attack = Attack(\n",
    "    goal_function, constraints, transformation, search_method\n",
    ")\n",
    "\n",
    "from tqdm import tqdm # tqdm provides us a nice progress bar.\n",
    "from textattack.attack_results import SuccessfulAttackResult\n",
    "from textattack import Attacker\n",
    "from textattack import AttackArgs\n",
    "\n",
    "attack_args = AttackArgs(num_examples=10, disable_stdout=True)\n",
    "dataset = WikiDataset(dm, examples=pt)\n",
    "\n",
    "attacker = Attacker(attack, dataset, attack_args)\n",
    "\n",
    "results_iterable = attacker.attack_dataset()\n",
    "\n",
    "logger = CustomCSVLogger(color_method='html')\n",
    "\n",
    "# \n",
    "# Run attack\n",
    "# \n",
    "from tqdm import tqdm\n",
    "for result in results_iterable:\n",
    "    tqdm._instances.clear() # Doesn't fix the progress bar :-(\n",
    "    logger.log_attack_result(result)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def escape_mask(ex):\n",
    "    ex[\"original_text\"] = ex[\"original_text\"].replace('<mask>', '[mask]')\n",
    "    ex[\"perturbed_text\"] = ex[\"perturbed_text\"].replace('<mask>', '[mask]')\n",
    "    return ex\n",
    "\n",
    "display(HTML(logger.df.apply(escape_mask, axis=1).to_html(escape=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b054fae0-e2c6-4721-83fd-3c199e577730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>perturbed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pope [mask] iii [mask] alexandria (also known as <font color = blue>khail</font> [mask]) was the [mask] pope of alexandria [mask] patriarch of the see of st. mark (880 -- [mask]) .<SPLIT>in 882 , the governor of egypt , ahmad ibn tulun , forced khail to pay heavy contributions , forcing him to sell a church and some attached properties to the local jewish community .<SPLIT>this building was at one time believed to have later become the site of the cairo geniza .<SPLIT></td>\n",
       "      <td>pope [mask] iii [mask] alexandria (also known as <<font color = red>mask</font>> [mask]) was the [mask] pope of alexandria [mask] patriarch of the see of st. mark (880 -- [mask]) .<SPLIT>in 882 , the governor of egypt , ahmad ibn tulun , forced khail to pay heavy contributions , forcing him to sell a church and some attached properties to the local jewish community .<SPLIT>this building was at one time believed to have later become the site of the cairo geniza .<SPLIT></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mask] [mask] is a <font color = gray>male</font> former [mask] <font color = gray>tennis</font> player from china .<SPLIT></td>\n",
       "      <td><[mask]> [mask] is a <<font color = green>mask</font>> former [mask] <<font color = green>mask</font>> player from china .<SPLIT></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[mask] [mask] (born 30 november [mask]) is a turkish professional footballer .<SPLIT>he currently plays as a striker for [mask] [mask] .<SPLIT></td>\n",
       "      <td>[mask] [mask] (born 30 november [mask]) is a turkish professional footballer .<SPLIT>he currently plays as a striker for <[mask]> [mask] .<SPLIT></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', None) # show full width of showing cols\n",
    "\n",
    "def escape_mask(ex):\n",
    "    ex[\"original_text\"] = ex[\"original_text\"].replace('<mask>', '[mask]')\n",
    "    ex[\"perturbed_text\"] = ex[\"perturbed_text\"].replace('<mask>', '[mask]')\n",
    "    return ex\n",
    "\n",
    "display(HTML(logger.df[[\"original_text\", \"perturbed_text\"]].apply(escape_mask, axis=1).to_html(escape=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e83c1-a92d-4ef3-b08f-128263ab8a3a",
   "metadata": {},
   "source": [
    "## Wow, so weird!! ðŸ˜…"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
